{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "Копия дин классификатор на Райфаззен.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tLzNG_7xeV3"
      },
      "source": [
        "### libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMJiETQDxeV5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "import os\n",
        "from datetime import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import csv\n",
        "from keras.layers import Bidirectional\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbvPZhZkxeV9"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import statistics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ZDH-y4xeV-"
      },
      "source": [
        "from keras.layers import Input, Dense, Activation, Dropout,Lambda, LSTM, BatchNormalization, RNN\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdVwJeHIxeWA"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/dinamic/train_set.csv', index_col=None)\n",
        "categories = pd.read_csv('drive/My Drive/dinamic/mcc2big.csv', index_col=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-XQ66BTf_YM"
      },
      "source": [
        "## parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hHlloAkz1cD"
      },
      "source": [
        "L_win = 4 \n",
        "delta = 2\n",
        "\n",
        "week_test = 19\n",
        "week_train = 23\n",
        "week_test_2 = 27\n",
        "\n",
        "pred_cat = 63\n",
        "n_timesteps = 4\n",
        "parameter=4\n",
        "num_month_client=3\n",
        "\n",
        "NFILTERS = 64\n",
        "lr = 0.001\n",
        "BATCH_SIZE = 64\n",
        "NB_EPOCH = 10\n",
        "\n",
        "BiNFILTERS = 20\n",
        "BiNB_EPOCH = 30\n",
        "BIBATCH_SIZE = 32\n",
        "\n",
        "OPTIM = Adam(learning_rate=lr)\n",
        "\n",
        "BiNB_EPOCHS=30\n",
        "BiBATCH_SIZE=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iya4MOyRLCSg"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cmTu9ujxeWM"
      },
      "source": [
        "### data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--4-C0WdxeWN"
      },
      "source": [
        "def preprocessing_week():\n",
        "    #df is a set of transactions with the following fields:\n",
        "    #amount, customer_id, mcc, transaction_date\n",
        "    with open('drive/My Drive/dinamic/mcc2big.csv') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        next(reader, None)\n",
        "        catdict = {int(rows[0]): int(rows[1]) for rows in reader}\n",
        "    df['MCC87'] = df['mcc'].map(catdict)\n",
        "    df.dropna(inplace = True, subset = ['MCC87'])\n",
        "    df['MCC87'] = df['MCC87'].astype('int')\n",
        "    df['transaction_date'] = pd.to_datetime(df['transaction_date'], infer_datetime_format = True)\n",
        "    df['WEEK'] = df['transaction_date'].apply(lambda date: date.week)\n",
        "    return df\n",
        "\n",
        "def features_aggregation_week():\n",
        "    data_sum = preproc_data_week.groupby(['customer_id', 'MCC87', 'WEEK'], as_index = False)['amount'].sum()\n",
        "    data_sum['COUNT'] = preproc_data_week.groupby(['customer_id', 'MCC87', 'WEEK']).size().reset_index().iloc[:, -1]\n",
        "    labels, uniques = pd.factorize(data_sum['customer_id'])\n",
        "    data_sum['id'] = labels\n",
        "    table_N = data_sum.pivot_table(index = ['id','WEEK'], columns = 'MCC87', values = 'COUNT', fill_value = 0).reset_index()\n",
        "    return table_N\n",
        "\n",
        "def window(in_group, ind_ar):\n",
        "    istart = 0\n",
        "    istop = L_win + 1   \n",
        "    group = in_group.sort_values()    \n",
        "    indices = group.index\n",
        "    gr = group\n",
        "    while istop <= len(group):\n",
        "        m_start = gr.iloc[istart]\n",
        "        m_stop = gr.iloc[istop - 1]\n",
        "        if (m_stop - m_start) == L_win:\n",
        "            add_data = [group.name, group.iloc[istop - 1]]           \n",
        "            indxs = add_data + [it for it in indices[istart:istop]]\n",
        "            ind_ar.append(indxs)\n",
        "        istart += 1\n",
        "        istop += 1\n",
        "    return ind_ar   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAoYQqpMxeWQ"
      },
      "source": [
        "def train_test_split_week(week_test, updating = False):\n",
        "    ind_ar = []\n",
        "    table.groupby('id')['WEEK'].apply(lambda x: window(x, ind_ar))\n",
        "    df_indxs = pd.DataFrame(ind_ar, columns=['id','last_week'] + list(range(L_win + 1)))\n",
        "\n",
        "    ind_test = df_indxs[(df_indxs['last_week'] >= week_test) & (df_indxs['last_week'] < week_train)]\n",
        "    ind_test_2 = df_indxs[(df_indxs['last_week'] >= week_train) & (df_indxs['last_week'] < week_test_2)]\n",
        "\n",
        "    if updating == True:\n",
        "      ind_train = df_indxs[(df_indxs['last_week'] >= week_upd) & (df_indxs['last_week'] < week_test)]\n",
        "    else:\n",
        "      ind_train = df_indxs[(df_indxs['last_week'] >= 15) & (df_indxs['last_week'] < week_test)]\n",
        "\n",
        "    return ind_test, ind_train, ind_test_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssKGllmFxeWS"
      },
      "source": [
        "def count_categories():\n",
        "    NCATS = table.shape[1] - 2\n",
        "    return NCATS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cky_jnHcxeWX"
      },
      "source": [
        "### data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnLJWYUtxeWX"
      },
      "source": [
        "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
        "    def __init__(self, df, indexes, L_win, NCATS, batch_size):\n",
        "        self.data = df\n",
        "        self.batch_size = batch_size\n",
        "        self.ind = indexes\n",
        "        self.L_win = L_win\n",
        "        self.NCATS = NCATS\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.ind) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_ind = self.ind[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        Ck = batch_ind[:, 0]\n",
        "        month = batch_ind[:, 1] - 1\n",
        "        ind_x = batch_ind[:, -(self.L_win + 1) : -1]\n",
        "        ind_y = batch_ind[:, -1]\n",
        "\n",
        "        X = self.data[ind_x, : ]\n",
        "        Y = self.data[ind_y, :]\n",
        "        Y = np.where(self.data[ind_y,:], 1, 0)\n",
        "        X = X.reshape(self.batch_size, self.L_win, self.NCATS)\n",
        "        Y = Y.reshape(self.batch_size, self.NCATS) \n",
        "        return [X, Ck, month], Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92l-XUcRxeWY"
      },
      "source": [
        "### lstm predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnJg0r8-xeWZ"
      },
      "source": [
        "def create_model():\n",
        "    inp = Input(shape=(L_win, NCATS))\n",
        "    inp_ck = Input(shape = (1, ))\n",
        "    inp_m = Input(shape = (1, ))\n",
        "\n",
        "    lay = LSTM(NFILTERS, return_sequences = True)(inp)\n",
        "    lay2 = LSTM(NFILTERS)(lay)\n",
        "    trg_clf = Dense(NCATS, activation = 'sigmoid')(lay2)\n",
        "\n",
        "    model_clf = Model(inputs = [inp, inp_ck, inp_m], outputs = trg_clf)\n",
        "    model_clf.compile(loss = 'binary_crossentropy', optimizer = OPTIM, metrics = ['accuracy']) \n",
        "\n",
        "    return model_clf   \n",
        "\n",
        "def answers_for_classes(classA, classB):\n",
        "    ind_test_A = ind_test[ind_test['id'].isin(classA)]\n",
        "    ind_test_B = ind_test[ind_test['id'].isin(classB)]\n",
        "    y_pred_A, y_true_A = get_answers_for_classes(ind_test_A)\n",
        "    y_pred_B, y_true_B = get_answers_for_classes(ind_test_B)\n",
        "    ind_cat = table.columns.get_loc(pred_cat) - 2\n",
        "    return y_pred_A[:, ind_cat], y_true_A[:, ind_cat], y_pred_B[:, ind_cat], y_true_B[:, ind_cat]\n",
        "\n",
        "def get_answers_for_classes(ind_test):\n",
        "    model_RNN = create_model()\n",
        "    model_RNN.load_weights(\"LSTM.h5\")\n",
        "    g_test = DataGenerator(table.values[:,2:], ind_test.values, L_win, NCATS, BATCH_SIZE)\n",
        "    y_pred = model_RNN.predict_generator(generator=g_test)\n",
        "    y_true = np.vstack([g_test[i][1] for i in range(len(g_test))])\n",
        "    return y_pred, y_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sexelltq7fV"
      },
      "source": [
        "def train_and_predict(updating = False):\n",
        "    g_train = DataGenerator(table.values[:, 2:], ind_train.values, L_win, NCATS, BATCH_SIZE)\n",
        "\n",
        "    g_test = DataGenerator(table.values[:, 2:], ind_test.values, L_win, NCATS, BATCH_SIZE)\n",
        "    g_test2 = DataGenerator(table.values[:, 2:], ind_test_2.values, L_win, NCATS, BATCH_SIZE)\n",
        "  \n",
        "    model_RNN = create_model()\n",
        "    if updating == True:\n",
        "      model_RNN.load_weights(\"drive/My Drive/dinamic/LSTM.h5\")\n",
        "    \n",
        "    model_RNN.fit_generator(generator = g_train, validation_data = g_test, epochs = NB_EPOCH, verbose = 1)\n",
        "    model_RNN.save_weights('drive/My Drive/dinamic/LSTM.h5')\n",
        "\n",
        "    y_pred = model_RNN.predict_generator(generator = g_test)\n",
        "    y_pred2 = model_RNN.predict_generator(generator = g_test2)\n",
        "    y_true = np.vstack([g_test[i][1] for i in range(len(g_test))])\n",
        "    ind_cat = table.columns.get_loc(pred_cat) - 2\n",
        "    model_RNN.save_weights('LSTM.h5')\n",
        "    return y_pred[:, ind_cat], y_true[:, ind_cat], y_pred2[:, ind_cat]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0665Rk3fxeWd"
      },
      "source": [
        "### class inferring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utI2LmOGxeWe"
      },
      "source": [
        "def count_coefficient():\n",
        "\n",
        "  ind_test_loc, ind_train_loc = ind_test.copy(), ind_train.copy()\n",
        "  ind_test_loc2 = ind_test_2.copy()\n",
        "\n",
        "  #first interval\n",
        "  ind_test_loc['target'] = table.values[ind_test_loc.values[:, -1], table.columns.get_loc(pred_cat)]\n",
        "  ind_test_loc['target'] = np.where(ind_test_loc['target'], 1, 0)\n",
        "  ind_test_loc['predicted_prob'] = np.zeros(len(ind_test_loc))\n",
        "  ind_test_loc.iloc[:len(y_pred), ind_test_loc.columns.get_loc('predicted_prob')] = y_pred\n",
        "  ind_test_loc = ind_test_loc[:len(y_pred)]\n",
        "  ind_test_loc['num'] = abs(ind_test_loc['target'] - ind_test_loc['predicted_prob'])\n",
        "  num = ind_test_loc.groupby('id')['num'].sum()\n",
        "  den_n = ind_test_loc.groupby('id')['target'].count()\n",
        "  CE = num / den_n\n",
        "  CE = 1 - CE\n",
        "\n",
        "  #the second interval\n",
        "  ind_test_loc2['target'] = table.values[ind_test_loc2.values[:, -1], table.columns.get_loc(pred_cat)]\n",
        "  ind_test_loc2['target'] = np.where(ind_test_loc2['target'], 1, 0)\n",
        "  ind_test_loc2['predicted_prob'] = np.zeros(len(ind_test_loc2))\n",
        "  ind_test_loc2.iloc[:len(y_pred2), ind_test_loc2.columns.get_loc('predicted_prob')] = y_pred2\n",
        "  ind_test_loc2 = ind_test_loc2[:len(y_pred2)]\n",
        "  ind_test_loc2['num'] = abs(ind_test_loc2['target'] - ind_test_loc2['predicted_prob'])\n",
        "  num2 = ind_test_loc2.groupby('id')['num'].sum()\n",
        "  den_n2 = ind_test_loc2.groupby('id')['target'].count()\n",
        "  CE2 = num2 / den_n2\n",
        "  CE2 = 1 - CE2\n",
        "  return CE, CE2\n",
        "\n",
        "def predictability_classes(CE):\n",
        "    A, B = [], []\n",
        "    for c_id, ce in CE.items():\n",
        "        if (ce > statistics.median(CE)):\n",
        "            A.append(c_id)\n",
        "        else:\n",
        "            B.append(c_id)\n",
        "    return A, B   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNiV0r_axeWj"
      },
      "source": [
        "### class identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6gPnB5fxeWk"
      },
      "source": [
        "def train_test_split_for_class_identification():\n",
        "\n",
        "    ind = np.arange(week_test, week_train)\n",
        "    ind_test = np.arange(week_train, week_test_2)\n",
        "\n",
        "    X_train = table[table['WEEK'].isin(ind)]\n",
        "    X_train = X_train[X_train['id'].isin(CE.keys())]\n",
        "    X_test = table[table['WEEK'].isin(ind_test)]\n",
        "    X_test = X_test[X_test['id'].isin(CE2.keys())]\n",
        "\n",
        "    num_months = X_test.groupby('id').size()\n",
        "    valid_months = [c_id for c_id, num in num_months.items() if num > num_month_client]\n",
        "\n",
        "    X_test = X_test[X_test['id'].isin(valid_months)]\n",
        "\n",
        "    num_months_train = X_train.groupby('id').size()\n",
        "    valid_months_train = [c_id for c_id, num in num_months_train.items() if num > num_month_client]\n",
        "\n",
        "    X_train = X_train[X_train['id'].isin(valid_months_train)]\n",
        "\n",
        "    test_ids = np.unique(X_test['id'])\n",
        "\n",
        "    return X_train, X_test, test_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLqwfryUxeWl"
      },
      "source": [
        "def reshape_train_and_test(updating = False):\n",
        "    list_X, list_X_test = [], []\n",
        "    X_train, X_test, test_ids = train_test_split_for_class_identification()\n",
        "\n",
        "    un_ids = np.unique(X_train['id'])\n",
        "    Y = np.zeros(len(un_ids))\n",
        "    un_ids_test = np.unique(X_test['id'])\n",
        "    for c_id in un_ids:\n",
        "        cur = X_train[X_train['id'] == c_id][pred_cat].values\n",
        "        list_X.append(cur)\n",
        "    for i in range(len(un_ids)):\n",
        "        if un_ids[i] in A:\n",
        "            Y[i] = 0\n",
        "        elif un_ids[i] in B:\n",
        "            Y[i] = 1\n",
        "    for i in range(len(list_X)):\n",
        "        list_X[i] = list_X[i][-parameter:]\n",
        "    X = np.vstack(list_X)\n",
        "    X = X.reshape(len(list_X), n_timesteps, 1)\n",
        "    Y = pd.get_dummies(Y).values\n",
        "    Y = Y.reshape(len(list_X), 2)\n",
        "    for c_id in un_ids_test:\n",
        "        cur = X_test[X_test['id'] == c_id][pred_cat].values\n",
        "        list_X_test.append(cur)\n",
        "    \n",
        "    for i in range(len(list_X_test)):\n",
        "        list_X_test[i] = list_X_test[i][-parameter:]\n",
        "    \n",
        "    X_test_n = np.vstack(list_X_test)\n",
        "    X_test_n = X_test_n.reshape(len(list_X_test), n_timesteps, 1)\n",
        "\n",
        "    return X, Y, X_test_n, test_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsYG4LfDxeWn"
      },
      "source": [
        "def BiLSTM_model(updating = False):\n",
        "    X, Y, X_test_n, test_ids = reshape_train_and_test(updating = updating)\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(BiNFILTERS, input_shape=(n_timesteps, 1), \n",
        "                                 return_sequences = False)))\n",
        "    model.add(Dense(2, activation = 'softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "\n",
        "    X = X.astype('float32')\n",
        "    Y = Y.astype('float32')\n",
        "    X_test_n = X_test_n.astype('float32')\n",
        "    \n",
        "    if updating == True:\n",
        "      model(np.zeros((1,*X.shape[1:])))\n",
        "      model.load_weights('drive/My Drive/dinamic/BiLSTM.h5')\n",
        "    \n",
        "\n",
        "    model.fit(X, Y, epochs = BiNB_EPOCHS, batch_size = BiBATCH_SIZE, verbose=2)\n",
        "    \n",
        "    model.save_weights('drive/My Drive/dinamic/BiLSTM.h5')\n",
        "    yhat = model.predict(X_test_n).argmax(1)\n",
        "    \n",
        "    pred_A, pred_B = [], []\n",
        "    for i in range(len(yhat)):\n",
        "        if (yhat[i] == 0):\n",
        "            pred_A.append(test_ids[i])\n",
        "        else:\n",
        "            pred_B.append(test_ids[i])\n",
        "    return pred_A, pred_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "HOK2o-sLxeWo"
      },
      "source": [
        "### evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "SjMD4R8IxeWp"
      },
      "source": [
        "def make_err_df(y_true, y_pred):\n",
        "    return pd.DataFrame(np.vstack((y_true, y_pred)).transpose(), columns=['y_true','y_pred'])\n",
        "    \n",
        "def plot_PRC(errs, lim, colors, linestyles):\n",
        "    recalls = {}\n",
        "    for im, err in enumerate(errs):\n",
        "        ytrue = err['y_true'].values \n",
        "        ypred = err['y_pred'].values\n",
        "\n",
        "        precision, recall, thr = precision_recall_curve(ytrue, ypred)\n",
        "        area = auc(recall, precision)\n",
        "        clr = colors[im]\n",
        "        lns = linestyles[im]\n",
        "        plt.plot(recall, precision, linewidth = 2, color = clr, label = err.name, linestyle = lns)\n",
        "                \n",
        "        ind = np.argmin(recall > lim)    \n",
        "        if ind < len(thr):\n",
        "            r = recall[ind]\n",
        "        recalls[err.name] = r\n",
        "        \n",
        "        plt.xlabel('Recall', fontsize = 20)\n",
        "        plt.ylabel('Precision', fontsize = 20)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.title('PR curve',size = 20,weight = 'bold')\n",
        "        plt.legend()\n",
        "    return recalls, precision[ind], thr[ind], area"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04nEdFDRb3LY"
      },
      "source": [
        "def data_for_matrix(y_pred,threshold):\n",
        "  y_pred_matrix=np.zeros(shape=y_pred.shape)\n",
        "  for i in range(0,len(y_pred)):\n",
        "    if y_pred[i]>threshold:\n",
        "      y_pred_matrix[i]=1\n",
        "  return y_pred_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSbF129BxeWq"
      },
      "source": [
        "### spending prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfVhqUesxeWq"
      },
      "source": [
        "def infer(updating = False):\n",
        "    y_pred, y_true, y_pred2 = train_and_predict(updating = updating)\n",
        "    CE, CE2 = count_coefficient()\n",
        "    A, B = predictability_classes(CE)\n",
        "    y_pred_A, y_true_A, y_pred_B, y_true_B = answers_for_classes(A, B)\n",
        "    pred_A, pred_B = BiLSTM_model(updating = updating)\n",
        "    y_pred_est_A, y_true_est_A, y_pred_est_B, y_true_est_B = answers_for_classes(pred_A, pred_B)\n",
        "\n",
        "    return y_pred, y_true, y_pred_A, y_true_A, y_pred_B, y_true_B, y_pred_est_A, y_true_est_A, y_pred_est_B, y_true_est_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# experiment"
      ],
      "metadata": {
        "id": "YISWdB586-XB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zblwXX_X8yKH"
      },
      "source": [
        "preproc_data_week = preprocessing_week()\n",
        "table = features_aggregation_week()\n",
        "NCATS = count_categories()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [7, 5]\n",
        "colors = ['k','g','r','g', 'r']\n",
        "linestyles = ['-', '-', '-', '-', '-']"
      ],
      "metadata": {
        "id": "wx2arAYeHtgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for j in range(1,10): #9 steps\n",
        "  if j == 1:\n",
        "    updating_for_step = False\n",
        "  else:\n",
        "    updating_for_step = True\n",
        "\n",
        "  ind_test, ind_train, ind_test_2 = train_test_split_week(week_test, updating = updating_for_step)\n",
        "  y_pred, y_true, y_pred2 = train_and_predict(updating = updating_for_step)\n",
        "  CE, CE2 = count_coefficient()\n",
        "  A, B = predictability_classes(CE)\n",
        "  y_pred_LSTM, y_true_LSTM, y_pred_A, y_true_A, y_pred_B, y_true_B, y_pred_est_A, y_true_est_A, y_pred_est_B, y_true_est_B = infer(updating = updating_for_step)\n",
        "\n",
        "  larger_elements = [element for element in y_true_LSTM if element > 0]\n",
        "  freq = len(larger_elements) / len(y_true_LSTM)\n",
        "\n",
        "  err_RNN = make_err_df(y_true_LSTM, y_pred_LSTM)\n",
        "  err_RNN.name = 'All data'\n",
        "\n",
        "  err_RNN_A = make_err_df(y_true_A, y_pred_A)\n",
        "  err_RNN_A.name = 'High predictability class'\n",
        "\n",
        "  err_RNN_B = make_err_df(y_true_B, y_pred_B)\n",
        "  err_RNN_B.name = 'Low predictability class'\n",
        "\n",
        "  err_RNN_est_A = make_err_df(y_true_est_A, y_pred_est_A)\n",
        "  err_RNN_est_A.name = 'High predictability class (estimated)'\n",
        "\n",
        "  err_RNN_est_B = make_err_df(y_true_est_B, y_pred_est_B)\n",
        "  err_RNN_est_B.name = 'Low predictability class (estimated)'\n",
        "\n",
        "  print(\"Step number \", j)\n",
        "\n",
        "  plt.plot([0, 1], [freq, freq], label = 'Event frequency', linewidth=2, linestyle='-', color = 'b')\n",
        "  recalls = plot_PRC([err_RNN, err_RNN_A, err_RNN_B], 0.5, colors, linestyles)\n",
        "  plt.show()\n",
        "  plt.plot([0, 1], [freq, freq], label = 'Event frequency', linewidth=2, linestyle='-', color = 'b')\n",
        "  recalls = plot_PRC([err_RNN, err_RNN_est_A, err_RNN_est_B], 0.5, colors, linestyles)\n",
        "  plt.show()\n",
        "\n",
        "  week_test = week_test + delta\n",
        "  week_train = week_train + delta\n",
        "  week_test_2 = week_test_2 + delta\n",
        "  week_upd = week_test - delta"
      ],
      "metadata": {
        "id": "GSI3lTI6-EK7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}